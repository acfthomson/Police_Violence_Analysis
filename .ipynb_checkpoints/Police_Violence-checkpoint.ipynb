{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib inline magic command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import psycopg2\n",
    "from config import db_password\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from os import walk\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Model Selection and Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Model imports\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c27afb21e200>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report_imbalanced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Sci-kit Learn Metrics imports\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cbd8616db01f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Imbalanced Learn imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEasyEnsembleClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Imbalanced Learn imports\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS\n",
    "def getDBengine():\n",
    "    user = 'postgres'\n",
    "    passw = 'db_passw'\n",
    "    host = 'policekillings.cv95lgysyvwq.us-east-1.rds.amazonaws.com'\n",
    "    port = 5432\n",
    "    database = 'PoliceKillings'\n",
    "    engine_1 = create_engine(f'postgres://' + user + ':' + passw + '@' + host + ':' + str(port) + '/' + database , \n",
    "                             pool_recycle=3600, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database into DataFrame\n",
    "def getData1():\n",
    "    s_statement = \"SELECT * FROM public.police_description\"\n",
    "    # df = pd.read_sql(s_statement, con=getDBengine())\n",
    "    try:\n",
    "        df = pd.read_sql(s_statement, con=getDBengine1())\n",
    "    except:\n",
    "        df = pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "#file_path = 'Resources/2013-2020_Police_Killings_Revised.xlsx' \n",
    "#killings_df = pd.read_excel(file_path)                         \n",
    "#killings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "killings_df.rename(columns = {\"Victim's age\" : 'Victim_Age', \"Victim's gender\" : 'Victim_Gender', \n",
    "                              \"Victim's race\" : 'Victim_Race', 'Date of Incident (month/day/year)' : 'Date',\n",
    "                              'Agency responsible for death' : 'Responsible_Agency', 'Cause of death' : 'Cause_of_Death',\n",
    "                              'A brief description of the circumstances surrounding the death' : 'Brief_Description',\n",
    "                              'Criminal Charges?' : 'Criminal_Charges', 'Symptoms of mental illness?' : 'Mental_Illness', \n",
    "                              'Armed/Unarmed Status' : 'Armed_Status', 'Alleged Threat Level (Source: WaPo)' : 'Threat_Level', \n",
    "                              'Fleeing (Source: WaPo)' : 'Fleeing', 'Body Camera (Source: WaPo)' : 'Body_Camera', \n",
    "                              'Encounter Type (DRAFT)' : 'Encounter_Type', \n",
    "                              'Initial Reported Reason for Encounter (DRAFT)' : 'Initial_Reason_for_Encounter',\n",
    "                              'Call for Service? (DRAFT)' : 'Call_for_Service'}, inplace = True)\n",
    "\n",
    "killings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Gender column\n",
    "del killings_df['Victim_Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null values\n",
    "for column in killings_df.columns:\n",
    "    print(f'Column {column} has {killings_df[column].isnull().sum()} null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty/blank values for Age, Threat_Level, Fleeing, Body_Camera, Encounter_Type, Initial_Reason_for_Encounter, \n",
    "# Call_for_Service and re-verify null values\n",
    "\n",
    "# Column: Age\n",
    "killings_df['Victim_Age'].replace({'Unknown': '0'}, inplace = True) # Possible to fill in 'Unknown' with mean\n",
    "                                                                    # of column?\n",
    "# Column: Threat_Level\n",
    "killings_df['Threat_Level'].replace({None: 'undetermined'}, inplace = True)\n",
    "\n",
    "# Column: Fleeing\n",
    "killings_df['Fleeing'].replace({None: 'unknown'}, inplace = True)\n",
    "\n",
    "# Column: Body_Camera\n",
    "killings_df['Body_Camera'].replace({None: 'unknown'}, inplace = True)\n",
    "\n",
    "# Column: Encounter_Type\n",
    "killings_df['Encounter_Type'].replace({None: 'Unknown'}, inplace = True)\n",
    "\n",
    "# Column: Initial_Reason_for_Encounter\n",
    "killings_df['Initial_Reason_for_Encounter'].replace({None: 'unknown'}, inplace = True)\n",
    "\n",
    "# Column: Call_for_Service\n",
    "killings_df['Call_for_Service'].replace({None: 'Unavailable'}, inplace = True)\n",
    "\n",
    "# Verify null values\n",
    "for column in killings_df.columns:\n",
    "    print(f'Column {column} has {killings_df[column].isnull().sum()} null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "killings_df = killings_df.dropna(how = 'any')\n",
    "killings_df = killings_df.reset_index().drop(['index'], axis = 1)\n",
    "killings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killings_df['Brief_Description'][4532]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect column data types\n",
    "killings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change Victim_Age data type from object to int\n",
    "killings_df['Victim_Age'] = killings_df['Victim_Age'].astype(str).astype(int)\n",
    "killings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from Date and create new column Year\n",
    "killings_df['Year'] = pd.DatetimeIndex(killings_df['Date']).year\n",
    "\n",
    "# Extract month from Date and create new column Month\n",
    "killings_df['Month'] = pd.DatetimeIndex(killings_df['Date']).month\n",
    "\n",
    "# Extract day from Date and create new column Day\n",
    "killings_df['Day'] = pd.DatetimeIndex(killings_df['Date']).day\n",
    "\n",
    "# Get day of week from Date and create new column Day_of_Week\n",
    "killings_df['Day_of_Week'] = killings_df['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get holiday from Date and create new column Holiday\n",
    "dr = pd.date_range(start='2013-01-01', end='2021-04-18')\n",
    "df = pd.DataFrame()\n",
    "df['Date'] = dr\n",
    "\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "\n",
    "killings_df['Holiday'] = killings_df['Date'].dt.date.astype('datetime64').isin(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#killings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies() to transform text values into numerical values\n",
    "killings_encoded = pd.get_dummies(killings_df, columns = \n",
    "                                  ['Cause_of_Death', 'Mental_Illness', 'Armed_Status', 'Threat_Level', 'Fleeing', 'Body_Camera', \n",
    "                                   'Geography'])\n",
    "\n",
    "killings_encoded.head()\n",
    "\n",
    "# We are keeping race because that is what our model will be running against, right?  Age was converted to an \n",
    "# int and Date is now datetime\n",
    "# Are we deleting the columns that are not in killings_encoded then?  I took notes on this during the tutor\n",
    "# session, but they do not make sense to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "X = pd.get_dummies(killings_df.drop(columns = ['race']))\n",
    "\n",
    "# Create target\n",
    "y = pd.DataFrame(killings_df['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check balance of target values\n",
    "y['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, and split model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state = 78,\n",
    "                                                    stratify = y)\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the Standard Scaler with the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML model code\n",
    "# Still need to pick a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate balanced accuracy score\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List feature sorted in descending order by feature importance - is this needed?\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "print(rf_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
